* How To Design Programs                                   :programming:lisp:
** Part 1: Fixed-Size Data

What did I learn?

*** The Design Recipe

When given a problem to solve, approach it like this.
1. Create data definitions for the data consumed and produced by the function on the basis of previously defined data structures.
2. Use these data definitions to create a function signature and header describing what the function does.
3. Create a function template by adding all the variables consumed by a function to the body of the function with placeholders in between.
4. Articulate examples of inputs and their desired outputs, and then build unit tests from those examples.
5. Write the function.
6. Test.
7. Revise and repeat until the function passes all checks.

*** Data Definitions

Defining data used by a program helps clarify thoughts, both for translation into code and for one's own reasoning. Here's the general pattern:
A PositiveNumber is a Number:
- >0
You can use this to create structs, as well:
A PositiveVector is a Structure:
(make-posvec PositiveNumber PositiveNumber)
Following this set of guidelines constrains your reasoning by forcing you to reason purely in terms of previously defined data structures (see above) - an extremely generative constraint.

*** Composition

Every programming textbook talks about composing functions. But many of them spend all their time talking about data structures and none of their time talking about design as a process, so you're always left to refactor code into composable functions after the fact. The approach of HTDP is virtually guaranteed to reduce technical debt right from the start by making composition approachable and an everyday part of the process.

*** The Lisp evaluation model

It's deceptively simple: left-to-right substitution of expressions for their results. This is the language of the lambda calculus - the core of Lisp's enduring power and appeal.

** Part 2: Arbitrarily Large Data
*** <2017-09-20 Wed>

Taking the subway home last night while working on the introduction to recursion in HTDP section two, I immediately felt like a very portable laptop was worth it when I quickly jumped ahead of the text to implement a recursive function that counted the size of a list and started to work on my own version of a map function. 

When I got off the subway, however, I realized that my naive implementation of the map function would probably run into issues that quotation (e.g. the distinction between use and mention of a lisp expression) would be necessary to solve. I don't think quotation is in the "Beginning Student" language that the early sections use. 

Still, a pretty good indication that the text does an excellent job portraying recursion as a powerful idea. 
* Functional Programming In Scala                         :programming:scala:
** Chapter 1

The chapter uses the example of a program to handle the buying of a cup of coffee to depict the notions of referential transparency and the substitution model in practice. A function is referentially transparent iff for all referentially transparent inputs it returns one and only one result. This property means that every expression in a pure function can be substituted for its result without changing the overall meaning of the function, facilitating the ability to locally reason about different parts of a function without worrying about how those parts interact with the rest of the function. These ideas seemed very intuitive after having completed HTDP intermezzo 1. 

** Chapter 2

The syntax of Scala is introduced through a tail-recursive function, which took me a fair bit to wrap my head around. I knew that they were desirable because they didn't have to add a new function to the call stack, but I didn't really "get it" until I had a fuzzy mental image like a series of cards being pulled from a stack as the function repeatedly applied its if-or-else rule to produce the factorial.

* Weapons of Math Destruction :math:political-economy:
** Chapter 1: Bomb Parts

O'Neil introduces the book with the three constituent features of a WMD: damage, opacity, and scale.

** Chapter 2: Shell Shocked

O'Neil describes her path of disillusionment through finance and ad-tech, and in so doing seems to predict my future.

** Chapter 3: Arms Race

The US News and World Report's college rankings as WMD: their chief damage was the lack of affordability as a metric, but they also distorted the admissions process by incentivizing selectivity.

** Chapter 6: Ineligible to Serve

O'Neil uses discrimination against job applicants (on the basis of language skills or mental profile) to argue that the algorithms designed to identify "problematic" traits can be used either to help people in need, or to discriminate. What makes the difference is the goals and values in which the analyses are embedded.

** Chapter 7: Sweating Bullets

O'Neil argues that despite promises to change from the top, WMDs can very deeply embed themselves into the incentive structure of companies.

** Chapter 8: Collateral Damage

O'Neil outlines the game that SITO is looking to get into: consumer risk modeling.

** Conclusion

A cri de coeur for regulation in an industry that thrives on bullshit, opacity, and techno-utopianism.

* The Stack                                     :political-economy:technology:
  :PROPERTIES:
  :AUTHOR:   Benjamin Bratton
  :END:

Address layer
Universal addressability all but guarantees that multiple independent users and networks will have their own addressing schemas, intertwined but also incompatible with many others. Direct object to object communication without human oversight might surprise us with unexpected ecologies of objects communicating and exchanging resources in wholly novel ways.


* Essential Scala :programming:scala:
Typelevel's free ebook on Scala fundamentals for experienced programmers. 

** Chapter 1
I skipped this because I'm already up and running with [[http://ensime.github.io/][ENSIME]].
** Chapter 2
2.2.5.1 Operator style
#+begin_src scala 
"foo".take(1) == "foo" take 1
1 + 2 + 3 == 1.+(2).+(3)
#+end_src
2.2.5.2 Substitution
#+begin_src scala 
1 + 2 + 3 == 6

#+end_src
2.3 
The literal types in scala are:
1. Numbers:
   1. Int - 32bit integer
   2. Double - 64bit floating point
   3. Float - 32bit floating point
   4. Long - 64bit integer
2. Booleans:
   1. true
   2. false
3. Characters - 16bit unicode values in quotes
4. Strings
5. Null (considered harmful)
6. Unit ()

2.3.8.1 Literally Just Literals
42 - value: 42, type: Int
true - value: true, type: Boolean
123L - value: 123, type: Long
42.0 - value: 42.0, type: Double

2.3.8.2 Quotes and Misquotes
'a' vs "a"

The former is a Char, the latter is a String.

2.3.8.3  An Aside on Side-Effects
~"Hello world!"~ is a string literal with a value of ~"Hello world!"~,
~println("Hello world!")~ is an expression with a value of Unit.
2.3.8.4 Learning by Mistakes
~'Hello world!'~ triggers an error because it encloses more than a single character in single quotes.
2.4 Object literals

2.4.5.1 Cats!

#+begin_src scala

object Oswald {
  val color = "Black"
  val food = "Milk"
}

object Henderson {
  val color = "Ginger"
  val food = "Chips"
}

object Quentin {
  val color = "Tabby and white"
  val food = "Curry"
}

#+end_src

2.4.5.2 Square Dance!

#+begin_src scala

object calc {
  def square(i: Double): Double = {
    i * i
  }

  def cube(i: Double): Double = {
    square(i) * i
  }
}

#+end_src

2.5.4.3 Precise Square Dance

#+begin_src scala

object calc2 {
  def square(i: Double): Double = {
    i * i
  }

  def cube(i: Double): Double = {
    square(i) * i
  }
}

#+end_src

2.5.4.4 Order of evaluation

The final expression's value output is "3c31" and in the process of evaluating each sub-expression, it prints "b", then "a", then "c", then "a"  to the console.

2.4.5.5 Greetings, human

#+begin_src scala

object human {
  val firstName = "Homer"
  val lastName = "Simpson"
}

object alien {
  def greet(h: human.type): String = {
    "Greetings, " + h.firstName + "."
  }
}

#+end_src

Above, we can see how to define methods that operate on the values of singleton objects.

2.4.5.6 The value of methods

Methods are not values (functions are), nor are they expressions. This is because they cannot evaluate to a value without being called. Once they are called, methods are equivalent to expressions.

2.5 Writing methods

A design recipe for scala methods!

1. Identify the input and output types of the method.
2. Prepare test cases
3. Write the template of the method declaration using ???
4. Test the code and observe the failures
5. Work forwards from the input, or backwards from the output to build the body of the method
6. Run the code again and observe the tests pass

2.6 Conditionals and Blocks

Blocks always inherit the type of the final expression within them.

2.6.4.1 A classic rivalry

The type is ~String~, the value is ~"predator"~.

2.6.4.2 A less well known rivalry

The type is ~Any~, the value is 2001.

2.6.4.3 An if without an else

The return type is ~Any~ and the value is ~Unit~ (or ~()~ )

** Chapter 3

*** 3.1 Classes
#+begin_src scala

class Person {
  val firstName = "Noel"
  val lastName = "Welsh"
  def name = firstName + " " + lastName
}

val noel = new Person

object alien {
  def greet(p: Person) =
    "Greetings, " + p.firstName + " " + p.lastName
}


#+end_src

There's no point in making classes with (only) static fields!

3.1.2 Constructors

#+begin_src scala

class Person(first: String, last: String) {
  val firstName = first
  val lastName = last
  def name = firstName + " " + lastName
}

#+end_src

3.1.3 Default and Keyword Parameters

#+begin_src scala
def greet(firstName: String = "Some", lastName: String = "Body") =
  "Greetings, " + firstName + " " + lastName + "!"
#+end_src

3.1.6.2 Cats on the prowl

#+begin_src scala

class Cat(val name: String, val color: String, val food: String) {
  def describe = name + " is a " + color + " cat who loves " + food + "."
}

val meowz = new Cat("Meowzer", "Black", "steak")
val oswald = new Cat("Oswald", "Black", "milk")
val henderson = new Cat("Henderson", "Ginger", "chips")
val quentin = new Cat("Quentin", "Tabby and white", "curry")


#+end_src

3.1.6.2 Cats on the prowl

#+begin_src scala

object ChipShop {
  def willServe(cat: Cat): Boolean = {
    if (cat.food == "chips") true else false
  }
}

#+end_src

3.1.6.3 Directorial Debut

#+begin_src scala

class Director(val firstName: String, 
               val lastName: String, 
               val yearOfBirth: Int) {
  def name = firstName + " " + lastName
}

class Film(val name: String,
           val yearOfRelease: Int,
           val imdbRating: Double,
           val director: Director) {
  def directorsAge = yearOfRelease - director.yearOfBirth
  def isDirectedBy(d: Director): Boolean = {
  d == director
  }

  def copy(name: String = name,
           yearOfRelease: Int = yearOfRelease,
           imdbRating: Double = imdbRating,
           director: Director = director) = {
  new Film(name, yearOfRelease, imdbRating, director)
  }
}

#+end_src

3.1.6.4 A simple counter

#+begin_src scala

class Counter(val i: Int) {
  def inc(): Counter = {
    new Counter(i + 1)
  }

  def dec(): Counter = {
    new Counter(i - 1)
  }
}

val c1 = new Counter(1)
val c2 = new Counter(-1)

assert(c1.inc.i == 2)
assert(c2.dec.i == -2)


#+end_src

3.1.6.5 Counting Faster

#+begin_src scala

class Counter(val i: Int) {
  def inc(amt: Int = 1): Counter = {
    new Counter(i + amt)
  }

  def dec(amt: Int = 1): Counter = {
    new Counter(i - amt)
  }
}

val c1 = new Counter(1)
val c2 = new Counter(-1)

assert(c1.inc().i == 2)
assert(c2.dec().i == -2)

assert(c2.dec(3).i == -4)
assert(c1.inc(3).i == 4)

#+end_src

3.1.6.6 Additional counting

#+begin_src scala

class Adder(val amount: Int) {
   def add(in: Int) = in + amount
}

class Counter(val i: Int) {
  def inc(amt: Int = 1): Counter = {
    new Counter(i + amt)
  }

  def dec(amt: Int = 1): Counter = {
    new Counter(i - amt)
  }
  
  def adjust(a: Adder): Counter = {
    new Counter(a.add(i))
  }
}


#+end_src

*** 3.2 Objects as Functions

#+BEGIN_SRC scala

class Adder(val amount: Int) {
  def apply(in: Int): Int = in + amount
}
#+END_SRC

3.2.3 When is a Function not a Function?

"How close does function application syntax get us to creating truly reusable objects to do computations for us? What
are we missing?"

My answer: As far as I can tell, we don't yet have the other building blocks of abstraction: ways to apply a function to a collection, partial application, or ways of writing a function that yields another function as its output.

The book's answer: we don't yet have types, which is how you decompose class functionality into simple reusable units.

*** 3.3 Companion Objects
#+BEGIN_SRC scala
class Timestamp(val seconds: Long) {
 
}

object Timestamp {
   def apply(hours: Int, minutes: Int, seconds: Int): Timestamp =
    new Timestamp(hours*60*60 + minutes*60 + seconds)
}
#+END_SRC
My take on why companion objects are useful: because they separate runtime /data/ from compile-time /methods/.

Here's one example of why this might be useful that I thought of this morning: say you have a ~Timer~ class, which has a default ~length~ field of 20m that can be overridden at run-time to produce ~Timer~ objects with different countdown times. If you wanted to extend into a ~Pomodoro~ class with a ~waitTime~ field and corresponding method that waited before launching another timer, you could create the class by extending ~Timer~, thus automatically inheriting the default value of 20m.

**** 3.3.2.1 Friendly Person Factory
#+BEGIN_SRC scala

object Person {
  def apply(wholeName: String): Person = {
    val sp = wholeName.split(" ")
    new Person(sp(0), sp(1))
  }
}

class Person(val firstName: String, val lastName: String) {
  def name = firstName + " " + lastName
}

#+END_SRC
**** 3.3.2.2 Extended body of Work
#+BEGIN_SRC scala

class Director(val firstName: String, 
               val lastName: String, 
               val yearOfBirth: Int) {
  def name = firstName + " " + lastName
}

class Film(val name: String,
           val yearOfRelease: Int,
           val imdbRating: Double,
           val director: Director) {
  def directorsAge = yearOfRelease - director.yearOfBirth
  def isDirectedBy(d: Director): Boolean = {
  d == director
  }

object Director {
  def apply(firstName: String, lastName: String, yearOfBirth: Int): Director = {
    new Director(firstName, lastName, yearOfBirth)
  }

  def older(d1: Director, d2: Director): Director = {
    if (d1.yearOfBirth <= d2.yearOfBirth) d1 else d2
  }
}

object Film {
  def apply(val name: String,
            val yearOfRelease: Int,
            val imdbRating: Double,
            val director: Director): Film = {
    new Film(name, yearOfRelease, imdbRating, director)
  }

  def highestRating(f1: Film, f2: Film): Film = {
    if (f1.imdbRating >= f2.imdbRating) f1 else f2
  }

  def oldestDirectorAtTheTime(f1: Film, f2: Film): Film = {
    if (f1.directorsAge >= f2.directorsAge) f1 else f2
  }
}

#+END_SRC
**** 3.3.2.3 Type or value?

1. value   actual answer: type
2. value   actual answer: type
3. type    actual answer: value   
4. value   actual answer: value
5. my answer: type  actual answer: value

Things to keep in mind: every method defined on the companion object is a value, constructors are a part of the class (and therefore types), look at what is defined in the companion object vs what's defined in the class.
*** 3.4 Case classes
They take the boilerplate out of defining a class with sensible defaults. When you define a case class, you get a companion object for free, as well as a few convenience methods - the most important of which is the extractor pattern, which will come in handy for pattern matching later on.

You can also define a ~case object~ , which the same default methods as a case class for a singleton.

Case classes reduce the barrier to entry for defining your own types, which in turn gets you into the habit of adding type-safety to your program. In this sense they are an /affordance/ to Scala's more powerful features.
**** 3.4.5.1 Case Cats
#+BEGIN_SRC scala

case class Cat(color: String, food: String)

#+END_SRC
**** 3.4.5.2 Director v2
#+BEGIN_SRC scala

case class Director(firstName: String, lastName: String, yearOfBirth: String) {
  def name = firstName + " " + lastName
}

object Director {
  def older(director1: Director, director2: Director) = 
    if (director1.yearOfBirth < director2.yearOfBirth) director1 else director2
}


case class Film(name: String, yearOfRelease: Int, 
  imdbRaing: Double, director: Director) {
  def directorsAge = yearOfRelease - director.yearOfBirth
  def isDirectedBy(d: Director): Boolean = d == this.director

  def copy(name: String = name, 
           yearOfRelease: Int = yearOfRelease,
           imdbRating: Double = imdbRating,
           director: Director = director) = {
    new Film(name, yearOfRelase, imdbRating, director)
  }

}
// case classes auto-create companion objects, but we can add to them
object Film {
  def newer(film1: Film, film2: Film): Film = 
    if (film1.yearOfRelease < film2.yearOfRelease) film1 else film2

  def highestRating(film1: Film, film2: Film): Double = {
    val rating1 = film1.imdbRating
    val rating2 = film2.imdbRating
    if (rating1 > rating2) rating1 else rating2
  }
  def oldestDirectorAtTheTime(film1: Film, film2: Film): Director = 
    if (film.directorsAge > film2.directorsAge) film1.director else film2.director
}

#+END_SRC

What's the difference between the methods that go in the class and the methods that go in the companion object? While the methods in the companion object might make reference to the run-time data of /other/ Film/Director objects, they do not refer to /their own/ run-time data - they can be used without instantiating an object in addition to the two objects being compared in the method ~highestRating~, for example.

* Spark: The Definitive Guide

** Shuffling
#+begin_quote
"The slower repartition method will also shuffle data across the network to achieve even load balancing." (ch. 19)
#+end_quote
Does this mean that if you call ~repartition(n)~ on a DF (where n is the number of existing partitions), then you automatically avoid some data skew?

#+BEGIN_QUOTE
"Another frequent source of performance enhancements is moving filters to the earliest part of your Spark job that you can. Sometimes, these filters can be pushed into the data sources themselves and this means that you can avoid reading and working with data that is irrelevant to your end result. Enabling partitioning and bucketing also helps achieve this." (ch. 19)
#+END_QUOTE

If we're reading in a large dataset and then filtering by one of its partitions, do we need to call ~coalesce~ on it to ensure that there's less of a shuffle overhead?  No. Filtering by the partition ensures a smaller number of partitions by default

Will calling ~repartition~ with a lower number of partitions simultaneously achieve the load balancing and reduced partitioning steps? Will this make a difference once it gets to the partitioning step?

#+begin_quote
"In general, we recommend having at least two or three tasks per CPU core in your cluster if the stage processes a large amount of data." (ch. 19)
#+end_quote 



#+begin_quote
"If a full garbage collection is invoked multiple times before a task completes, it means that there isn’t enough memory available for executing tasks, so you should decrease the amount of memory Spark uses for caching (spark.memory.fraction)." (ch. 19)
#+end_quote

#+begin_quote
"Note that with large executor heap sizes, it can be important to increase the G1 region size with -XX:G1HeapRegionSize." (ch. 19)
#+end_quote

For uncommon use cases like ~collect_list~ on a large dataset, then this might be a necessary step - removing large result rows of collected data probably invokes the GC pretty frequently. 
