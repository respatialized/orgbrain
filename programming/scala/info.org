* Scala
   :PROPERTIES:
   :ID:       295a3ef6-10e2-4faf-95ee-88bcbc248b92
   :BRAIN_PARENTS: 67069e3b-0693-4cd6-8429-949de721e47e
   :END:

#+BEGIN_description 
Functional programming and category theory on the JVM.
#+END_description 

A JVM language with strong foundations in category theory. Used often for distributed data-intensive applications with frameworks like Akka, Storm, and Spark. 
* Scala Deck :deck: 
** first n                                                             :note:
   :PROPERTIES:
   :ANKI_NOTE_TYPE: Basic
   :END:
*** Front
    get first n elements of sequence in scala
*** Back
#+begin_src scala  
seq.take(n)
#+end_src
** concat sequences                                                    :note:
   :PROPERTIES:
   :ANKI_NOTE_TYPE: Basic
   :END:
*** Front
    combine two sequences in Scala
*** Back
#+begin_src scala 
seq1 ++ seq2
#+end_src
* Apache Spark

#+BEGIN_description 
Distributed, fault-tolerant data processing for data pipelines and large-scale data science.
#+END_description 

** Spark Deck :deck: 
*** udf on list of columns                                             :note:
    :PROPERTIES:
    :ANKI_NOTE_TYPE: Basic
    :END:
**** Front
     apply a udf to a list of columns in spark
**** Back
#+begin_src scala 
var tempdf = df
cols.map{c => tempdf.withColumn(c, udf(col(c)))}
#+end_src 
*** select column sequence                                             :note:
    :PROPERTIES:
    :ANKI_NOTE_TYPE: Basic
    :END:
**** Front
select a sequence of column names in Spark
**** Back
#+begin_src scala 
df.select(cols.head, cols.tail: _*)
#+end_src

*** basic model                                                        :note:
    :PROPERTIES:
    :ANKI_NOTE_TYPE: Basic
    :END:

**** Front
High-level summary of any Spark program

**** Back
1. represent data as collection of RDDs
2. build up a series of lazy transformations on those RDDs
3. perform actions to get the results of those transformations
